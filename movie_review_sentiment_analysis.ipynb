{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movie Review Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data are from preserved datasets in nltk library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     C:\\Users\\Zhimin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk                           \n",
    "nltk.download(\"movie_reviews\")         \n",
    "from nltk.corpus import movie_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neg/cv000_29416.txt',\n",
       " 'neg/cv001_19502.txt',\n",
       " 'neg/cv002_17424.txt',\n",
       " 'neg/cv003_12683.txt',\n",
       " 'neg/cv004_12641.txt',\n",
       " 'pos/cv995_21821.txt',\n",
       " 'pos/cv996_11592.txt',\n",
       " 'pos/cv997_5046.txt',\n",
       " 'pos/cv998_14111.txt',\n",
       " 'pos/cv999_13106.txt']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#'neg/...' means it contains negative review, and 'pos/...' positive review\n",
    "files=movie_reviews.fileids()\n",
    "files[:5]+files[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Train and test dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first shuffle files randomly \n",
    "from random import shuffle\n",
    "shuffle(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into 80% train and 20% test\n",
    "train=files[:1600]\n",
    "test=files[1600:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=[movie_reviews.raw(movie) for movie in train]\n",
    "X_test=[movie_reviews.raw(movie) for movie in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the y label\n",
    "def label(file):\n",
    "    if file[:3]=='pos':\n",
    "        return 'positive'\n",
    "    else:\n",
    "        return 'negative'\n",
    "\n",
    "y_train=[label(file) for file in train]\n",
    "y_test=[label(file) for file in test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser','tagger','ner','textcat'])\n",
    "\n",
    "def tokenize_lemma(text):\n",
    "    \"\"\"\n",
    "    function to stem the words, eg: 'apple', 'apples' both return 'apple'\n",
    "    \"\"\"\n",
    "    return [w.lemma_ for w in nlp(text)]\n",
    "\n",
    "#since text is stemmed, stop_words should also be stemmed.\n",
    "stop_words_lemma = set(w.lemma_ for w in nlp(' '.join(STOP_WORDS)))\n",
    "\n",
    "vectorizer=TfidfVectorizer(stop_words=stop_words_lemma, tokenizer=tokenize_lemma)\n",
    "classifier=SGDClassifier(max_iter=50)\n",
    "\n",
    "pipe=Pipeline([('vectorizer', vectorizer), ('classifier', classifier)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zhimin\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.855"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#grid search to find the best estimater\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters={#(1,1) means features are single word, (1,2) has single word but also has phrase\n",
    "            'vectorizer__ngram_range':[(1,1), (1,2)],\n",
    "            #alpha is regularization parameter, the smaller, the heavier regu;arization\n",
    "           'classifier__alpha': (0.001, 0.0001, 0.00001),\n",
    "            #log means linear regression, hinge means linear SVM\n",
    "           'classifier__loss': ('log', 'hinge')}\n",
    "\n",
    "gridsearch=GridSearchCV(pipe, parameters, cv=5)\n",
    "gridsearch.fit(X_train, y_train)\n",
    "gridsearch.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the best model\n",
    "best_model=gridsearch.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words={'anyone', 'fifteen', 'whereby', 'therein', 'until', 'whereupon', 'name', 'we', 'hence', 'take', 'the', 'far', 'when', 'fifty', 'once', 'nevertheless', 'wherein', 'one', 'toward', 'show', 'otherwise', 'by', 'while', 'her', 'indeed', 'top', 'too', 'beside', 'much', 'below', 'nowhere', 'yet...ometime', 'such', 'full', 'myself', '\\ufeff1', 'only', 'six', 'whereafter', 'eight', 'quite', 'any'},\n",
       "        strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=<function tokenize_lemma at 0x0000028F6A395F28>,\n",
       "        use_idf=True, vocabulary=None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the parameters in vectorizer of best model\n",
    "best_model.named_steps['vectorizer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=1e-05, average=False, class_weight=None,\n",
       "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "       l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=50,\n",
       "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
       "       validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the parameters in classifier of the best model\n",
    "best_model.named_steps['classifier']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vectorizer', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=...m_state=None, shuffle=True, tol=None,\n",
       "       validation_fraction=0.1, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.fit(X_train+X_test, y_train+y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get some of reviews about movie <Abe> from Rotten Tomatoes\n",
    "review=[\"With a more streamlined script, or even fewer characters and more developed relationships, \\\"Abe\\\" could have made a real impact. As it stands, there are too many cooks in the kitchen.\",\n",
    "       \"A great measure of \\\"Abe\\\"'s success is that it made me hungry. More than that, it's the first movie in quite some time to make me smile.\",\n",
    "       \"Abe could have been one unforgettable meal, but instead, its aftertaste is barely memorable.\"\n",
    "       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['negative', 'positive', 'positive'], dtype='<U8')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.predict(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
